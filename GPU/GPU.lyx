#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage {url}
\usepackage [numbers]{natbib}
\date{}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 2cm
\headsep 2cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Contemporary Computer Science - GPU, Many-core, and Cluster Computing
\end_layout

\begin_layout Author
Tom Robson - hzwr87
\end_layout

\begin_layout Section*
Step 1 - will need to rewrite much of this
\end_layout

\begin_layout Standard
Before attempts are made to improve the performance of the karman code,
 we must examine its current characteristics.
 This has been done using the Intel VTune performance analysis tool, with
 
\begin_inset Formula $t=0.1$
\end_inset

 in the main while loop for reasonable execution time.
 The types of analysis used for this project were General Exploration, Advanced
 Hotspots and HPC Performance Characterisation.
 
\end_layout

\begin_layout Standard
From running these analysis methods, it has been determined that the key
 hotspots are in the functions computeP and setPressureBoundaryConditions.
 These functions are linked, as computeP calls setPressureBoundaryConditions,
 giving us a clear idea that the main issues for this algorithm lie in its
 implementation of pressure.
 From a closer examination of the computeP function, we can see that the
 main bottleneck in this function comes from line 668, given here:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

p[getCellIndex(ix,iy,iz)] += -omega * residual / 6.0 * getH() * getH();
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This line is so computationally expensive because it performs complex mathematic
al functions at floating point precision, meaning that it has a high CPI
 rate.
 The General Exploration analysis states that the primary bottleneck in
 this line comes from the Back-End of the pipeline, with the majority of
 this being as a result of a memory bound, where the Back-End cannot accept
 new operations due to existing operations still running.
 This function also has a substantial core bound, meaning that some of the
 execution ports have become saturated.
 The results of the Advanced Hotspots analysis reveal that this line also
 consumes a large proportion of the CPU time.
 The HPC analysis supports the General Exploration in the fact that there
 is a substantial memory bound present in the whole computeP function, and
 this line in particular.
 
\end_layout

\begin_layout Standard
When examining setPressureBoundaryConditions more closely, the General Explorati
on analysis tells us that this function is limited by the Front-End of the
 pipeline.
 The majority of this is caused by Front-End bandwidth, meaning that not
 all the slots in the pipeline are filled, rather than Front-End latency,
 where none of the slots are filled.
 
\end_layout

\begin_layout Standard
To address these issues, the performance model that should be applied is
 Strong Scaling.
 To calculate the possible speedup due to parallelisation over 
\begin_inset Formula $p$
\end_inset

 processors, was must apply the equation 
\begin_inset Formula $S(p)=\frac{t(1)}{t(p)}$
\end_inset

, where 
\begin_inset Formula $t(1)$
\end_inset

 is the time taken on one processor, and the 
\begin_inset Formula $t(p)$
\end_inset

 is the time taken over p processors.
\begin_inset Formula $t(p)$
\end_inset

 can be calculated using Amdahl's law, 
\begin_inset Formula $t(p)=f.t(1)+\frac{(1-f).t(1)}{p}$
\end_inset

, where 
\begin_inset Formula $f$
\end_inset

 is the fraction of the code that is not parallelisable.
 As computeP is the main hotspot for this code, this must be the target
 of the parallelisation.
 Therefore, the non parallelisable part of the code is everything but computeP.
 These to formulae can be combined and simplified to give 
\begin_inset Formula $S(p)=\frac{1}{f+\frac{(1-f)}{p}}$
\end_inset

.
 To calculate the maximum possible speedup, we will assume 
\begin_inset Formula $p$
\end_inset

 tends to infinity.
 USE FIGURES FROM HAMILTON
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Step 2
\end_layout

\begin_layout Standard
To break up the computational domain into blocks, or subproblems, we must
 first determine a suitable block size.
 The size chosen for these blocks is 4x4x4.
 To facilitate the process of computation, it has been decided to restrict
 the grid dimensions to be multiples of 4, supplied by the first command
 line argument.
 If this is not supplied correctly, the system will error.
 To allocate cells to blocks, we loop through the cells that would be in
 the top left corner of each block, and for all cells in the block, check
 if the obstacle is present in any of these cells.
 These blocks are enumerated by a counter, and if a block contains the obstacle,
 this is stored in an array of booleans, with the index in the array indicating
 which block the boolean refers to.
 This process is performed in setupScenario().
\end_layout

\begin_layout Standard
The benefits of this process can be realised in computeP, the main hotspot
 of this code, to improve its run-time.
 We loop through each block, and if it doesn't contain the obstacle, we
 can vectorise the loops for the cells in this block using Intel's SIMD
 pragmas.
 If it does contain the obstacle, then the computation must be done in the
 same way as before.
 Due to the small size of the obstacle, the majority of the blocks can have
 SIMD vectorisation applied to them, so this modification results in a substanti
al increase in the time taken to run the simulation.
 
\end_layout

\begin_layout Standard

\series bold
Now collect results from Hamilton
\end_layout

\begin_layout Standard

\series bold
Ben - As a guide: I got 2x by using vectorisation
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Step 3
\end_layout

\end_body
\end_document
